# Actividad 1.9
# Optimizaci贸n de Rutas Log铆sticas con Apache Spark

Este proyecto implementa un algoritmo de **Caminos M铆nimos (Shortest Path)** distribuido utilizando **Apache Spark (PySpark)**. El objetivo es calcular la distancia m铆nima desde una ciudad de origen a todas las dem谩s ciudades en una red log铆stica modelada como un grafo dirigido y ponderado.

El algoritmo emplea un enfoque iterativo de **relajaci贸n tipo Dijkstra** (*Dijkstra-style relaxation*), adaptado para ejecutarse en paralelo mediante el paradigma MapReduce.

---

##  Tabla de Contenidos
- [Descripci贸n del Proyecto](#descripci贸n-del-proyecto)
- [Arquitectura del Algoritmo](#arquitectura-del-algoritmo)
- [Requisitos e Instalaci贸n](#requisitos-e-instalaci贸n)
- [Estructura del Repositorio](#estructura-del-repositorio)
- [Ejecuci贸n](#ejecuci贸n)

---

##  Descripci贸n del Proyecto

El problema consiste en encontrar la ruta m谩s eficiente (menor coste/distancia) en una red de distribuci贸n. Dado que las redes log铆sticas reales pueden ser masivas, se utiliza Spark para procesar el grafo de manera distribuida.

El sistema modela cada ciudad como un nodo y cada carretera como una arista con peso. A trav茅s de iteraciones sucesivas, el algoritmo propaga las distancias conocidas hasta converger en la soluci贸n 贸ptima.

---

## Arquitectura del Algoritmo: Map & Reduce

El n煤cleo de la soluci贸n se basa en dos funciones que transforman el RDD (Resilient Distributed Dataset) en cada iteraci贸n.

### Estado del Nodo
Cada nodo en el RDD se representa con la siguiente tupla:
` (ID_Nodo, (Lista_Vecinos, Distancia_Acumulada, Es_Activo, Historial_Ruta)) `

### 1. Fase Map: Expansi贸n (`dijkstra_map`)
Esta funci贸n act煤a como el **"Mensajero"**. Toma el estado actual de un nodo y decide si debe propagar informaci贸n a sus vecinos.

* **Entrada:** El estado completo de un nodo.
* **Salida:** Una lista de mensajes (tuplas) para ser procesados.

**Mecanismos clave:**
* **Persistencia (Autoconservaci贸n):** La funci贸n siempre emite una copia del propio nodo. Esto es fundamental porque en Spark, si no re-emitimos el nodo, este desaparecer铆a del RDD en la siguiente iteraci贸n. Se emite con el estado `Activo = False` tras ser procesado.
* **Propagaci贸n (Relajaci贸n):** Si el nodo est谩 marcado como **Activo** (significa que su distancia mejor贸 en la iteraci贸n anterior), calcula la nueva distancia potencial para sus vecinos:
  $$D_{nuevo} = D_{actual} + Peso_{arista}$$
  Posteriormente, env铆a un "mensaje" de actualizaci贸n a cada vecino.
  > *Nota:* A los vecinos se les env铆a una lista de adyacencia vac铆a `[]` para ahorrar memoria, ya que el objetivo es solo comunicar la nueva distancia propuesta.

### 2. Fase Reduce: Selecci贸n (`dijkstra_reduce`)
Esta funci贸n act煤a como el **"Juez"**. Spark agrupa todos los mensajes destinados al mismo ID de nodo y ejecuta esta funci贸n para colapsarlos en un solo estado.

**Mecanismos clave:**
* **Recuperaci贸n de Topolog铆a:** Reconstruye la estructura del grafo. Dado que los mensajes de actualizaci贸n llegan con listas de vecinos vac铆as, la funci贸n prioriza la lista que contiene datos (la del mensaje de persistencia).
* **Selecci贸n Greedy (Codiciosa):** Compara las distancias recibidas y conserva estrictamente la **menor**.
* **Activaci贸n:** Marca el nodo resultante como `Activo = True` **solo si hubo una mejora**. Esto disparar谩 una nueva expansi贸n en la siguiente iteraci贸n, simulando la "Active Frontier" de Dijkstra.

### 3. Convergencia
El algoritmo se ejecuta dentro de un bucle que monitoriza la cantidad de nodos activos. El proceso se detiene autom谩ticamente cuando:
` num_active_nodes == 0 `
Esto garantiza que no se desperdicien recursos computacionales una vez hallados todos los caminos m铆nimos.

---

## Requisitos e Instalaci贸n

### Prerrequisitos
* **Python 3.8+**
* **Java 8 u 11** (Necesario para el entorno de Spark)
* **Apache Spark**

### Instalaci贸n de Librer铆as
Ejecuta el siguiente comando para instalar las dependencias de Python:

```bash
pip install pyspark networkx matplotlib
